# app/services/summary.py
# -*- coding: utf-8 -*-
from __future__ import annotations
from typing import Tuple, List, Optional
import json, re
import asyncio
import itertools

try:
    import google.generativeai as genai
except Exception:
    genai = None

# --- NEW: lightweight lang tools for Lite/AI output normalization ---
try:
    from langdetect import detect as _ld_detect
except Exception:
    _ld_detect = None

try:
    from deep_translator import GoogleTranslator as _GT
except Exception:
    _GT = None

from app.config import settings

# DEBUG
import logging

LOG = logging.getLogger("summary")


def _system_prompt(lang: str) -> str:
    if (lang or "").lower().startswith("fa"):
        return (
            "Ø®Ø±ÙˆØ¬ÛŒ ÙÙ‚Ø· ÙØ§Ø±Ø³ÛŒ Ùˆ Ø±ÙˆØ§Ù† Ø¨Ø§Ø´Ø¯. Ù„Ø­Ù† ØªØ­Ù„ÛŒÙ„ÛŒ Ùˆ Ú©Ø§Ø±Ø¨Ø±Ø¯ÛŒ.\n"
            "Ø¯Ù‚ÛŒÙ‚Ø§Ù‹ Ùˆ ÙÙ‚Ø· ÛŒÚ© JSON Ø¨Ø§ Ú©Ù„ÛŒØ¯Ù‡Ø§ÛŒ Ø²ÛŒØ± Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†Ø› Ù‡ÛŒÚ† Ù…ØªÙ† Ø§Ø¶Ø§ÙÙ‡ Ù†Ù†ÙˆÛŒØ³. "
            'Ø§Ú¯Ø± Ù‡Ø± Ø¨Ø®Ø´ÛŒ Ø¯Ø§Ø¯Ù‡Ù” Ú©Ø§ÙÛŒ Ù†Ø¯Ø§Ø´ØªØŒ Ù…Ù‚Ø¯Ø§Ø± Ù‡Ù…Ø§Ù† Ø¨Ø®Ø´ Ø±Ø§ Ø®Ø§Ù„ÛŒ Ø¨Ú¯Ø°Ø§Ø± (Ø¢Ø±Ø§ÛŒÙ‡Ù” Ø®Ø§Ù„ÛŒ [] ÛŒØ§ Ø±Ø´ØªÙ‡Ù” Ø®Ø§Ù„ÛŒ "").\n'
            "{"
            '"tldr":"Û±â€“Û³ Ø¬Ù…Ù„Ù‡Ù” Ø¬Ù…Ø¹â€ŒØ¨Ù†Ø¯ÛŒ ØªØ­Ù„ÛŒÙ„ÛŒØ› Ø§Ø² ØªÚ©Ø±Ø§Ø± Ø¹Ù†ÙˆØ§Ù† Ø®ÙˆØ¯Ø¯Ø§Ø±ÛŒ Ú©Ù†",'
            '"bullets":["Û³ ØªØ§ Û¶ Ù†Ú©ØªÙ‡Ù” Ù†ØªÛŒØ¬Ù‡â€ŒÙ…Ø­ÙˆØ±Ø› Ù‡Ø± Ù†Ú©ØªÙ‡ Ø¨Ø§ ÙØ¹Ù„ Ø´Ø±ÙˆØ¹ Ø´ÙˆØ¯"],'
            '"opportunities":["ÙØ±ØµØªâ€ŒÙ‡Ø§ÛŒ Ú©Ù„ÛŒØ¯ÛŒØŒ Ù…Ø®ØªØµØ± Ùˆ Ø¹Ù…Ù„ÛŒ"],'
            '"risks":["Ø±ÛŒØ³Ú©â€ŒÙ‡Ø§/Ù…Ø­Ø¯ÙˆØ¯ÛŒØªâ€ŒÙ‡Ø§ØŒ Ø´ÙØ§Ù Ùˆ ÙˆØ§Ù‚Ø¹â€ŒÚ¯Ø±Ø§ÛŒØ§Ù†Ù‡"],'
            '"signal":"ÛŒÚ© Ù¾ÛŒØ§Ù…/Ø³ÛŒÚ¯Ù†Ø§Ù„ Ú©Ø§Ø±Ø¨Ø±Ø¯ÛŒ Ø¨Ø±Ø§ÛŒ Ø®ÙˆØ§Ù†Ù†Ø¯Ù‡ (Ø¯Ø± ÛŒÚ© ÛŒØ§ Ø¯Ùˆ Ø¬Ù…Ù„Ù‡)"'
            "}\n"
            "Ø§Ú¯Ø± Ø¯Ø§Ø¯Ù‡ Ù†Ø§Ú©Ø§ÙÛŒ Ø¨ÙˆØ¯ØŒ Ù…Ø­ØªØ§Ø·Ø§Ù†Ù‡ Ø®Ù„Ø§ØµÙ‡ Ú©Ù†Ø› Ø§Ù…Ø§ Ø¨Ø§Ø² Ù‡Ù… ÙÙ‚Ø· Ù‡Ù…ÛŒÙ† JSON Ø±Ø§ Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†."
        )
    return (
        "Output must be in clear English with an analytical, practical tone.\n"
        "Return EXACTLY one JSON object with the keys below and nothing else. "
        'If any section lacks sufficient content, leave it empty (use [] for lists and "" for strings).\n'
        "{"
        '"tldr":"1â€“3 analytical sentences; do not repeat the title",'
        '"bullets":["3â€“6 action-oriented key points; each starts with a verb"],'
        '"opportunities":["Concise, actionable opportunities"],'
        '"risks":["Clear, realistic risks/limitations"],'
        '"signal":"One concise, practical takeaway for the reader"'
        "}\n"
        "If content is limited, summarize cautiously; still return ONLY this JSON."
    )


_CLEAN_BULLET_PREFIX = re.compile(r"^[â€¢\-â€“â€”\*\u2022\+\s]+")


def _dedupe_cap(bullets: List[str], cap: int = 6) -> List[str]:
    seen, out = set(), []
    for b in bullets or []:
        b = _CLEAN_BULLET_PREFIX.sub("", (b or "").strip())
        b = re.sub(r"\s+", " ", b)
        if len(b) < 8:
            continue
        key = b.lower()
        if key in seen:
            continue
        seen.add(key)
        out.append(b)
        if len(out) >= cap:
            break
    return out


def _strip_code_fences(s: str) -> str:
    return re.sub(
        r"^```(?:json)?|```$", "", (s or "").strip(), flags=re.I | re.M
    ).strip()


# ---------- NEW: translate helpers ----------
def _detect_lang(s: str) -> str:
    """fa/en/.. or '' if unknown"""
    if not s or not _ld_detect:
        return ""
    try:
        return (_ld_detect(s) or "").split("-", 1)[0].lower()
    except Exception:
        return ""


def _translate(s: str, target: str) -> str:
    """Translate using deep-translator; if unavailable, return s."""
    if not s:
        return s
    t = (target or "").lower()
    if not t or not _GT:
        return s
    try:
        return _GT(source="auto", target=t).translate(s)
    except Exception:
        return s


def _force_lang(
    tldr: str, bullets: List[str], target_lang: str
) -> Tuple[str, List[str]]:
    """
    If summary_strict is enabled or detected language != target, translate.
    Works for both AI and Lite outputs.
    """
    tgt = (target_lang or "").lower()
    if not tgt:
        return tldr, bullets

    strict = str(getattr(settings, "summary_strict", "false")).lower() == "true"

    # quick language guess from concatenated text
    sample = " ".join(([tldr] if tldr else []) + bullets)[:400]
    src = _detect_lang(sample)

    must_translate = strict or (src and src != tgt)
    if not must_translate:
        return tldr, bullets

    tldr_t = _translate(tldr, tgt) if tldr else ""
    bullets_t = [_translate(b, tgt) for b in (bullets or [])]
    return tldr_t or tldr, bullets_t or bullets


# ---------- NEW: language enforcement for premium fields ----------
def _force_lang_full(
    tldr: str,
    bullets: List[str],
    opportunities: List[str],
    risks: List[str],
    signal: str,
    target_lang: str,
) -> Tuple[str, List[str], List[str], List[str], str]:
    """
    Ù‡Ù…Ø§Ù† Ù…Ù†Ø·Ù‚ _force_lang Ø§Ù…Ø§ Ø±ÙˆÛŒ Ù‡Ù…Ù‡Ù” ÙÛŒÙ„Ø¯Ù‡Ø§ÛŒ Ù¾Ø±Ù…ÛŒÙˆÙ… Ù†ÛŒØ² Ø§Ø¹Ù…Ø§Ù„ Ù…ÛŒâ€ŒØ´ÙˆØ¯.
    """
    tldr2, bullets2 = _force_lang(tldr, bullets, target_lang)

    tgt = (target_lang or "").lower()
    if not tgt:
        return tldr2, bullets2, opportunities, risks, signal

    # ØªØµÙ…ÛŒÙ… ØªØ±Ø¬Ù…Ù‡ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù‡Ù…Ø§Ù† Ø´Ø±Ø· Ø³Ø®Øªâ€ŒÚ¯ÛŒØ±Ø§Ù†Ù‡
    strict = str(getattr(settings, "summary_strict", "false")).lower() == "true"
    sample = " ".join(
        (opportunities or []) + (risks or []) + ([signal] if signal else [])
    )[:400]
    src = _detect_lang(sample)
    must_translate = strict or (src and src != tgt)

    if not must_translate:
        return tldr2, bullets2, opportunities, risks, signal

    opp2 = [_translate(x, tgt) for x in (opportunities or [])]
    risk2 = [_translate(x, tgt) for x in (risks or [])]
    sig2 = _translate(signal, tgt) if signal else signal
    return tldr2, bullets2, opp2 or opportunities, risk2 or risks, sig2 or signal


# --------------------------------------------


def _extract_json(raw: str) -> str:
    """
    Ø³Ø¹ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ù‡ Ø§Ø² Ù…ØªÙ† Ø®Ø§Ù… Gemini ÙÙ‚Ø· JSON Ø®Ø§Ù„Øµ Ø±Ùˆ Ø¨Ú©Ø´Ù‡ Ø¨ÛŒØ±ÙˆÙ†.
    """
    if not raw:
        return "{}"
    # Ø­Ø°Ù Ø¨Ù„Ø§Ú©â€ŒÙ‡Ø§ÛŒ ```json ... ```
    cleaned = re.sub(r"^```(?:json)?|```$", "", raw.strip(), flags=re.I | re.M).strip()
    # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ø§ÙˆÙ„ÛŒÙ† Ùˆ Ø¢Ø®Ø±ÛŒÙ† { }
    start = cleaned.find("{")
    end = cleaned.rfind("}")
    if start != -1 and end != -1 and end > start:
        return cleaned[start : end + 1]
    return cleaned


# Get API Key
import itertools

# Round-Robin Ø¨Ø¬Ø§ÛŒ random
_key_cycle = None


def get_gemini_key() -> str:
    global _key_cycle
    if not settings.gemini_keys:
        return ""
    if _key_cycle is None:
        _key_cycle = itertools.cycle(settings.gemini_keys)
    return next(_key_cycle)


# ---------- Lite summary (kept disabled) ----------
# def _lite_summary(title: str, text: str) -> Tuple[str, List[str]]:
#     """
#     Heuristic TLDR + bullets from the raw text (no AI).
#     Used as a robust fallback when AI fails or input is very short.
#     """
#     src = (text or "").strip()
#     if not src:
#         return "", []
#     # Ú©ÙˆØªØ§Ù‡â€ŒØ³Ø§Ø²ÛŒ Ùˆ Ø¬Ø³ØªØ¬ÙˆÛŒ Ø¬Ù…Ù„Ø§Øª Ù…Ø¹Ù†ÛŒâ€ŒØ¯Ø§Ø±
#     sentences = re.split(r"(?<=[.!ØŸ\?])\s+", src)
#     # tldr: Ø¯Ùˆ Ø¬Ù…Ù„Ù‡ Ø§ÙˆÙ„ ÛŒØ§ Ø¹Ù†ÙˆØ§Ù† + Ø¬Ù…Ù„Ù‡ Ø§ÙˆÙ„
#     tldr_candidates = [s for s in sentences if len(s) > 20]
#     tldr = ""
#     if tldr_candidates:
#         tldr = " ".join(tldr_candidates[:2]).strip()
#     else:
#         # Ø§Ú¯Ø± Ø¬Ù…Ù„Ù‡ Ø¨Ù„Ù†Ø¯ Ù†Ø¯Ø§Ø´ØªØŒ Ø¨Ø±Ø¯Ø§Ø± Ø§Ø² Ù…ØªÙ† Ú©ÙˆØªØ§Ù‡â€ŒØªØ±
#         tldr = (src[:200]).strip()

#     # bullets: Ø®Ø·ÙˆØ·/Ø¬Ù…Ù„Ø§Øª Ú©Ù‡ ÙØ¹Ù„ Ø¯Ø§Ø±Ù†Ø¯ ÛŒØ§ Ø·ÙˆÙ„Ø§Ù†ÛŒ Ù‡Ø³ØªÙ†Ø¯
#     points: List[str] = []
#     for line in re.split(r"[\n\r]+", src):
#         l = line.strip()
#         if not l:
#             continue
#         if len(l) < 30:
#             continue
#         if any(
#             k in l.lower()
#             for k in (
#                 "should",
#                 "will",
#                 "can",
#                 "lead",
#                 "include",
#                 "increase",
#                 "reduce",
#                 "cause",
#                 "help",
#                 "need",
#                 "Ø§Ø³Øª",
#                 "Ù…ÛŒâ€ŒØ´ÙˆØ¯",
#                 "Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯",
#                 "Ø®ÙˆØ§Ù‡Ø¯",
#             )
#         ):
#             points.append(l)
#         if len(points) >= getattr(settings, "summary_max_bullets", 4):
#             break

#     if not points:
#         # fallback: Ø¨Ø±Ø¯Ø§Ø± Ø¬Ù…Ù„Ø§Øª Ø·ÙˆÙ„Ø§Ù†ÛŒâ€ŒØªØ±
#         long_sents = [s for s in sentences if len(s) > 40]
#         points = long_sents[: getattr(settings, "summary_max_bullets", 4)]

#     bullets = _dedupe_cap(points, cap=getattr(settings, "summary_max_bullets", 4))
#     # enforce language lightly
#     tldr, bullets = _force_lang(tldr, bullets, getattr(settings, "prompt_lang", "fa"))
#     return tldr, bullets


async def _call_ai(model, prompt: str) -> str:
    """ÛŒÚ© ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ Ø§Ù…Ù† Ø¨Ù‡ Gemini Ú©Ù‡ raw text Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†Ø¯ ÛŒØ§ ''."""
    try:
        resp = await model.generate_content_async(prompt)
        raw = _strip_code_fences(getattr(resp, "text", "") or "")
        return raw
    except Exception as ex:
        LOG.debug("_call_ai_once failed: %s", ex)
        return ""


class Summarizer:
    """
    Summary chain with Gemini primary and Lite fallback.
    Guarantees (tldr, bullets). Enforces user language if possible.
    """

    print("ğŸ”‘ Gemini using key:", get_gemini_key())

    def __init__(self, api_key: Optional[str], prompt_lang: str = "fa"):
        self.api_key = api_key
        self.prompt_lang = (prompt_lang or "fa").lower()
        self._fail_count = 0
        self._cooldown_until: Optional[float] = None

    async def summarize_full(
        self, title: str, text: str, author: Optional[str] = None
    ) -> Tuple[str, List[str], List[str], List[str], str]:
        """
        ØªÙ„Ø§Ø´ Ú†Ù†Ø¯Ù…Ø±Ø­Ù„Ù‡â€ŒØ§ÛŒ Ø­Ø¯Ø§Ú©Ø«Ø±ÛŒ Ø±ÙˆÛŒ Gemini. Ø§Ú¯Ø± Ù†ØªØ§ÛŒØ¬ JSON Ù†Ø¨ÙˆØ¯Ù†Ø¯
        ØªÙ„Ø§Ø´ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ… TLDR/bullets Ø±Ø§ Ø§Ø² Ù…ØªÙ† Ø®Ø§Ù… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ú©Ù†ÛŒÙ….
        """
        title = (title or "").strip()
        text = (text or "").strip()
        base = (
            text
            if len(text) > getattr(settings, "summary_lite_min_len", 120)
            else f"{title}\n{text}"
        ).strip()
        if not base:
            return "", [], [], [], ""

        if not (genai and self.api_key):
            LOG.debug("summarize_full: no genai or api key")
            return "", [], [], [], ""

        try:
            api_key = get_gemini_key()
            genai.configure(api_key=api_key)
            print("ğŸ”‘ Gemini using key===", api_key)

            model = genai.GenerativeModel(settings.summary_model_name)
        except Exception as ex:
            LOG.exception("summarize_full: model init failed: %s", ex)
            return "", [], [], [], ""


        # ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù‚Ø§Ø¨Ù„ ØªØºÛŒÛŒØ± Ø¯Ø± config:
        max_attempts = int(getattr(settings, "summary_max_attempts", 6))
        short_threshold = int(getattr(settings, "summary_short_threshold", 120))
        max_input = int(getattr(settings, "summary_max_input_chars", 6000))

        # prompt Ù‡Ø§ÛŒ Ù…Ø±Ø­Ù„Ù‡â€ŒØ§ÛŒ (Ø§Ø² Ø³Ø®Øª Ø¨Ù‡ Ù†Ø±Ù…)
        system = _system_prompt(self.prompt_lang)
        strict_json_prompt = (
            system + f"\nTitle: {title or '-'}\nContent:\n{(base or '')[:max_input]}"
        )
        softer_prompt = (
            strict_json_prompt
            + "\nIf you cannot output full JSON, try at least to return tldr and bullets in JSON."
        )
        unstructured_prompt = (
            "Provide a concise TLDR (1 sentence) and 2-4 short action bullets. "
            'If possible return JSON like {"tldr":"...","bullets":[...]}. Otherwise plain text is fine.\n'
            + f"Title: {title or '-'}\nContent:\n{(base or '')[:max_input]}"
        )
        just_tldr_prompt = (
            "Provide a single concise TLDR (one sentence) only.\n"
            + f"Title: {title}\nContent:\n{(base or '')[:max_input]}"
        )
        just_bullets_prompt = (
            "Provide 2-4 short action-oriented bullets only (one per line).\n"
            + f"Title: {title}\nContent:\n{(base or '')[:max_input]}"
        )

        prompt_sequence = [strict_json_prompt, softer_prompt, unstructured_prompt]
        if len(base) < short_threshold:
            prompt_sequence.append(just_tldr_prompt)
            prompt_sequence.append(just_bullets_prompt)
        prompt_sequence = prompt_sequence[:max_attempts]

        raw_collected = ""
        parsed_obj = {}

        def extract_from_raw(raw: str) -> dict:
            """Ø³Ø¹ÛŒ Ø¯Ø± Ø§Ø³ØªØ®Ø±Ø§Ø¬ JSON ÛŒØ§ ØªÚ©Ù‡â€ŒÙ‡Ø§ÛŒ Ù…ÙÛŒØ¯ Ø§Ø² Ù…ØªÙ† Ø®Ø§Ù…."""
            if not raw:
                return {}
            # 1) JSON extraction
            jtxt = _extract_json(raw)
            try:
                obj = json.loads(jtxt)
                if isinstance(obj, dict):
                    return obj
            except Exception:
                pass
            # 2) regex-based TLDR extraction
            # look for lines starting with TLDR, TL;DR, Summary:
            lines = [ln.strip() for ln in raw.splitlines() if ln.strip()]
            out = {}
            for ln in lines[:5]:
                low = ln.lower()
                if (
                    low.startswith("tldr")
                    or low.startswith("tl;dr")
                    or low.startswith("summary")
                ):
                    # take after ":" if exists
                    if ":" in ln:
                        out["tldr"] = ln.split(":", 1)[1].strip()
                    else:
                        out["tldr"] = ln.strip()
                    break
            # bullets: lines that start with -, â€¢, or numbered
            bullets = []
            for ln in lines:
                if ln.startswith(("-", "â€¢", "*")) or re.match(r"^\d+[\).\s]", ln):
                    cleaned = re.sub(r"^[\-\â€¢\*\d\.\)\s]+", "", ln).strip()
                    if len(cleaned) > 10:
                        bullets.append(cleaned)
            if bullets:
                out.setdefault("bullets", bullets)
            # fallback: if still empty, first sentence as tldr
            if not out.get("tldr"):
                first_sent = re.split(r"(?<=[.!ØŸ\?])\s+", raw.strip())
                if first_sent:
                    out["tldr"] = first_sent[0][:300]
            return out

        # ØªÙ„Ø§Ø´ Ù…Ø±Ø­Ù„Ù‡â€ŒØ§ÛŒ
        for idx, p in enumerate(prompt_sequence, 1):
            raw = await _call_ai(model, p)
            LOG.debug(
                "summarize_full attempt %d raw_len=%d title=%r",
                idx,
                len(raw or ""),
                title,
            )
            if not raw:
                continue
            raw_collected = raw
            parsed = extract_from_raw(raw)
            if (
                parsed.get("tldr")
                or parsed.get("bullets")
                or parsed.get("opportunities")
                or parsed.get("risks")
                or parsed.get("signal")
            ):
                parsed_obj = parsed
                LOG.debug(
                    "summarize_full: parsed from attempt %d -> keys=%s",
                    idx,
                    list(parsed.keys()),
                )
                break

        if not parsed_obj:
            raw = await _call_ai(model, just_tldr_prompt)
            parsed = extract_from_raw(raw)
            if parsed.get("tldr") or parsed.get("bullets"):
                parsed_obj = parsed
                LOG.debug("summarize_full: got fallback tldr/bullets")

        if not parsed_obj:
            if raw_collected:
                parsed_obj = extract_from_raw(raw_collected)
            else:
                return "", [], [], [], ""

        tldr = (parsed_obj.get("tldr") or "").strip()
        bullets = [x for x in (parsed_obj.get("bullets") or []) if isinstance(x, str)]
        opportunities = [
            x for x in (parsed_obj.get("opportunities") or []) if isinstance(x, str)
        ]
        risks = [x for x in (parsed_obj.get("risks") or []) if isinstance(x, str)]
        signal = (parsed_obj.get("signal") or "").strip()

        # caps Ùˆ dedupe
        bullets = _dedupe_cap(bullets, cap=getattr(settings, "summary_max_bullets", 4))
        opp_cap = int(
            getattr(
                settings,
                "summary_max_opportunities",
                getattr(settings, "summary_max_bullets", 4),
            )
        )
        risk_cap = int(
            getattr(
                settings,
                "summary_max_risks",
                getattr(settings, "summary_max_bullets", 4),
            )
        )
        opportunities = _dedupe_cap(opportunities, cap=opp_cap)
        risks = _dedupe_cap(risks, cap=risk_cap)

        try:
            tldr, bullets, opportunities, risks, signal = _force_lang_full(
                tldr, bullets, opportunities, risks, signal, self.prompt_lang
            )
        except Exception:
            LOG.debug("summarize_full: _force_lang_full failed", exc_info=True)

        return tldr or "", bullets or [], opportunities or [], risks or [], signal or ""

    async def summarize(
        self, title: str, text: str, author: Optional[str] = None
    ) -> Tuple[str, List[str]]:
        title = (title or "").strip()
        text = (text or "").strip()

        base = (
            text if len(text) > settings.summary_lite_min_len else f"{title}\n{text}"
        ).strip()
        if not base:
            return "", []

        # 1) try AI chain (multiple attempts inside _call_ai)
        tldr, bullets = await self._call_ai(title, base)

        # 2) if AI returned nothing, try lite heuristic
        # if not (tldr or bullets):
        #     tldr, bullets = _lite_summary(title, base)

        # 3) final normalization/enforce language
        try:
            tldr, bullets = _force_lang(tldr, bullets, self.prompt_lang)
        except Exception:
            pass

        return tldr or "", bullets or []
